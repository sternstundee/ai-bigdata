import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
import matplotlib.pyplot as plt
import os
import numpy as np
import warnings

warnings.filterwarnings('ignore')  # å¿½ç•¥æ— å…³è­¦å‘Š

# ---------------------- å®Œå…¨é€‚é…ä½ çš„æ•°æ®åˆ—ï¼ˆage/income/guding/VIP/loanï¼‰ï¼Œæ— éœ€ä¿®æ”¹ï¼----------------------
file_path = "D:/pythonstudy/aibdlesson/labor7/loan_YN.csv"  # ä½ çš„æ•°æ®è·¯å¾„
target_col = "loan"  # ç›®æ ‡åˆ—ï¼šè´·æ¬¾çŠ¶æ€ï¼ˆloanåˆ—ï¼‰


# ---------------------- 1. æ•°æ®è¯»å–ï¼ˆè‡ªåŠ¨é€‚é…ç¼–ç ï¼Œå…¼å®¹ä¸­æ–‡ï¼‰----------------------
def read_data_with_encoding(file_path):
    if file_path.endswith(".csv"):
        try:
            return pd.read_csv(file_path, encoding="gbk")  # Windowsä¸­æ–‡æ–‡ä»¶é»˜è®¤ç¼–ç 
        except UnicodeDecodeError:
            return pd.read_csv(file_path, encoding="utf-8-sig")
    else:
        raise ValueError("ä»…æ”¯æŒCSVæ–‡ä»¶ï¼ˆä½ çš„æ–‡ä»¶æ˜¯.csvï¼Œå·²é€‚é…ï¼‰")


try:
    # è¯»å–æ•°æ®
    df = read_data_with_encoding(file_path)
    print("=" * 70)
    print(f"âœ… æˆåŠŸè¯»å–è´·æ¬¾æ•°æ®ï¼š{df.shape[0]} æ¡æ ·æœ¬ï¼Œ{df.shape[1]} ä¸ªç‰¹å¾")
    print("æ•°æ®åˆ—åï¼š", list(df.columns))
    print("\næ•°æ®å‰5è¡Œé¢„è§ˆï¼š")
    print(df.head())
    print("\næ•°æ®ç±»å‹ï¼š")
    print(df.dtypes)
    print("=" * 70)

    # éªŒè¯ç›®æ ‡åˆ—ï¼ˆç¡®ä¿loanåˆ—å­˜åœ¨ï¼‰
    if target_col not in df.columns:
        raise ValueError(
            f"æ•°æ®ä¸­ä¸å­˜åœ¨loanåˆ—ï¼è¯·æ£€æŸ¥åˆ—åï¼š{list(df.columns)}\n"
            f"è‹¥ç›®æ ‡åˆ—åä¸åŒï¼Œè¯·ä¿®æ”¹ä»£ç ä¸­ target_col ä¸ºå®é™…åˆ—å"
        )

    # åˆ†ç¦»ç‰¹å¾ï¼ˆXï¼‰å’Œç›®æ ‡å˜é‡ï¼ˆyï¼‰ï¼šç‰¹å¾åˆ—=age/income/guding/VIPï¼Œç›®æ ‡åˆ—=loan
    X = df.drop(columns=[target_col])  # ç‰¹å¾åˆ—ï¼ˆæ’é™¤loanï¼‰
    y = df[target_col]  # ç›®æ ‡åˆ—ï¼šloanï¼ˆè´·æ¬¾çŠ¶æ€ï¼‰
    print(f"ğŸ“Š ç‰¹å¾åˆ—ï¼ˆç”¨äºé¢„æµ‹è´·æ¬¾ï¼‰ï¼š{list(X.columns)}")
    print(f"ğŸ¯ ç›®æ ‡åˆ—ï¼ˆè´·æ¬¾çŠ¶æ€ï¼‰ï¼š{target_col}ï¼ˆå–å€¼åˆ†å¸ƒï¼š{y.value_counts().to_dict()}ï¼‰")
    print("=" * 70)

    # ---------------------- 2. One-Hotç¼–ç ï¼ˆè‡ªåŠ¨è¯†åˆ«åˆ†ç±»/æ•°å€¼ç‰¹å¾ï¼‰----------------------
    # åˆ†ç±»ç‰¹å¾ï¼šgudingã€VIPï¼ˆé€šå¸¸æ˜¯å­—ç¬¦ä¸²æˆ–äºŒåˆ†ç±»æ ‡ç­¾ï¼‰
    # æ•°å€¼ç‰¹å¾ï¼šageï¼ˆå¹´é¾„ï¼‰ã€incomeï¼ˆæ”¶å…¥ï¼‰
    categorical_cols = X.select_dtypes(include=["object"]).columns.tolist()
    numeric_cols = X.select_dtypes(exclude=["object"]).columns.tolist()
    print(f"ğŸ”¤ åˆ†ç±»ç‰¹å¾ï¼ˆOne-Hotç¼–ç ï¼‰ï¼š{categorical_cols}")
    print(f"ğŸ”¢ æ•°å€¼ç‰¹å¾ï¼ˆç›´æ¥ä¿ç•™ï¼‰ï¼š{numeric_cols}")

    # One-Hotç¼–ç åˆ†ç±»ç‰¹å¾ï¼ˆé€‚é…sklearn 0.24.2ç‰ˆæœ¬ï¼‰
    vec = DictVectorizer(sparse=False)
    X_categorical_encoded = vec.fit_transform(X[categorical_cols].to_dict("records"))
    categorical_feature_names = vec.get_feature_names()

    # åˆå¹¶æ•°å€¼ç‰¹å¾å’Œç¼–ç åçš„åˆ†ç±»ç‰¹å¾
    if numeric_cols:
        X_numeric = X[numeric_cols].values
        X_encoded = np.hstack([X_numeric, X_categorical_encoded])
        all_feature_names = numeric_cols + categorical_feature_names
    else:
        X_encoded = X_categorical_encoded
        all_feature_names = categorical_feature_names

    print(f"\nğŸ”¥ One-Hotç¼–ç å®Œæˆï¼")
    print(f"ç¼–ç åç‰¹å¾çŸ©é˜µå½¢çŠ¶ï¼š{X_encoded.shape}ï¼ˆæ ·æœ¬æ•° Ã— ç¼–ç åç‰¹å¾æ•°ï¼‰")
    print(f"ç¼–ç åç‰¹å¾åç§°ï¼ˆå…± {len(all_feature_names)} ä¸ªï¼‰ï¼š")
    for i, name in enumerate(all_feature_names, 1):
        print(f"  {i:2d}. {name}")
    print("=" * 70)

    # ---------------------- 3. è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹ï¼ˆè´·æ¬¾çŠ¶æ€é¢„æµ‹ï¼‰----------------------
    dt_model = DecisionTreeClassifier(
        max_depth=3,  # é™åˆ¶æ ‘æ·±åº¦ï¼Œé¿å…è¿‡æ‹Ÿåˆï¼Œå¯è§†åŒ–æ¸…æ™°
        random_state=42,  # å›ºå®šéšæœºç§å­ï¼Œç»“æœå¯å¤ç°
        criterion="gini"  # åŸºå°¼ç³»æ•°ï¼ˆé€‚åˆåˆ†ç±»ä»»åŠ¡ï¼‰
    )
    dt_model.fit(X_encoded, y)  # è®­ç»ƒæ¨¡å‹

    # æ¨¡å‹è¯„ä¼°
    train_acc = dt_model.score(X_encoded, y)
    print("ğŸ¤– å†³ç­–æ ‘æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print(f"è®­ç»ƒé›†å‡†ç¡®ç‡ï¼š{train_acc:.3f}ï¼ˆè¶Šé«˜è¡¨ç¤ºæ¨¡å‹æ‹Ÿåˆæ•ˆæœè¶Šå¥½ï¼‰")
    print("=" * 70)

    # ---------------------- 4. å†³ç­–æ ‘å¯è§†åŒ–ï¼ˆä¿å­˜åˆ°labor7ç›®å½•ï¼‰----------------------
    plt.rcParams["font.sans-serif"] = ["SimHei"]  # ä¸­æ–‡æ”¯æŒ
    plt.rcParams["axes.unicode_minus"] = False  # è´Ÿå·æ˜¾ç¤ºæ­£å¸¸

    # ç»˜åˆ¶å†³ç­–æ ‘å¹¶ä¿å­˜
    plt.figure(figsize=(18, 10))
    plot_tree(
        dt_model,
        feature_names=all_feature_names,  # æ˜¾ç¤ºç‰¹å¾åç§°ï¼ˆå¦‚ageã€incomeã€VIP_æ˜¯ï¼‰
        class_names=[str(cls) for cls in dt_model.classes_],  # è´·æ¬¾çŠ¶æ€ç±»åˆ«ï¼ˆå¦‚0/1ã€æ˜¯/å¦ï¼‰
        filled=True,  # å½©è‰²å¡«å……ï¼ˆä¸åŒç±»åˆ«ä¸åŒé¢œè‰²ï¼‰
        rounded=True,  # åœ†è§’çŸ©å½¢
        fontsize=10,
        proportion=True  # æ˜¾ç¤ºæ ·æœ¬å æ¯”
    )
    dt_img_path = "D:/pythonstudy/aibdlesson/labor7/decision_tree_loan_final.png"
    plt.tight_layout()
    plt.savefig(dt_img_path, dpi=300, bbox_inches="tight")
    plt.show()
    print(f"ğŸ“¸ å†³ç­–æ ‘å›¾ç‰‡å·²ä¿å­˜åˆ°ï¼š{dt_img_path}ï¼ˆç›´æ¥æ‰“å¼€æŸ¥çœ‹ï¼‰")
    print("=" * 70)

    # ---------------------- 5. å¯¼å‡ºå†³ç­–æ ‘DOTæ–‡ä»¶ï¼ˆé«˜æ¸…ç‰ˆï¼‰----------------------
    dot_path = "D:/pythonstudy/aibdlesson/labor7/decision_tree_loan_final.dot"
    export_graphviz(
        dt_model,
        out_file=dot_path,
        feature_names=all_feature_names,
        class_names=[str(cls) for cls in dt_model.classes_],
        filled=True,
        rounded=True,
        proportion=True
    )
    print(f"ğŸ“„ å†³ç­–æ ‘DOTæ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{dot_path}")
    print("ğŸ’¡ é«˜æ¸…å›¾ç‰‡è½¬æ¢ï¼ˆå¯é€‰ï¼‰ï¼š")
    print("  1. å®‰è£…graphvizï¼šhttps://graphviz.org/download/ï¼ˆWindowsé€‰msiï¼Œå‹¾é€‰æ·»åŠ åˆ°PATHï¼‰")
    print("  2. å‘½ä»¤è¡Œè¿›å…¥labor7ç›®å½•ï¼Œæ‰§è¡Œï¼šdot -Tpng decision_tree_loan_final.dot -o decision_tree_loan_highres.png")
    print("=" * 70)

    # ---------------------- 6. æ ¸å¿ƒç‰¹å¾åˆ†æï¼ˆå½±å“è´·æ¬¾çš„å…³é”®å› ç´ ï¼‰----------------------
    feature_importance = pd.DataFrame({
        "ç‰¹å¾åç§°": all_feature_names,
        "é‡è¦æ€§": dt_model.feature_importances_
    }).sort_values("é‡è¦æ€§", ascending=False)

    print("ğŸ† å½±å“è´·æ¬¾çŠ¶æ€çš„å…³é”®ç‰¹å¾æ’åï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š")
    print(feature_importance.to_string(index=False))

    # å¯è§†åŒ–å…³é”®ç‰¹å¾
    plt.figure(figsize=(12, 6))
    plt.barh(
        feature_importance["ç‰¹å¾åç§°"][::-1],  # é€†åºæ˜¾ç¤ºï¼Œé‡è¦æ€§é«˜çš„åœ¨ä¸Šæ–¹
        feature_importance["é‡è¦æ€§"][::-1],
        color="#1f77b4"  # è“è‰²ç³»ï¼Œä¸“ä¸šç¾è§‚
    )
    plt.xlabel("ç‰¹å¾é‡è¦æ€§", fontsize=12)
    plt.title("è´·æ¬¾çŠ¶æ€é¢„æµ‹ - å†³ç­–æ ‘ç‰¹å¾é‡è¦æ€§æ’å", fontsize=14, fontweight="bold")
    plt.tight_layout()
    importance_img_path = "D:/pythonstudy/aibdlesson/labor7/feature_importance_loan_final.png"
    plt.savefig(importance_img_path, dpi=300)
    plt.show()
    print(f"\nğŸ“Š ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜åˆ°ï¼š{importance_img_path}")
    print("=" * 70)

    # ---------------------- 7. ä¿å­˜æ‰€æœ‰å®éªŒç»“æœï¼ˆç”¨äºä½œä¸šæäº¤ï¼‰----------------------
    # ä¿å­˜ç¼–ç åçš„æ•°æ®ï¼ˆå«ç›®æ ‡åˆ—ï¼‰
    encoded_df = pd.DataFrame(X_encoded, columns=all_feature_names)
    encoded_df[target_col] = y.values  # åˆå¹¶loanåˆ—
    result_csv_path = "D:/pythonstudy/aibdlesson/labor7/loan_onehot_dt_final_result.csv"
    encoded_df.to_csv(result_csv_path, index=False, encoding="utf-8-sig")

    # ä¿å­˜ç‰¹å¾é‡è¦æ€§æ•°æ®
    importance_csv_path = "D:/pythonstudy/aibdlesson/labor7/feature_importance_loan_final.csv"
    feature_importance.to_csv(importance_csv_path, index=False, encoding="utf-8-sig")

    print("ğŸ’¾ æ‰€æœ‰å®éªŒç»“æœå·²ä¿å­˜åˆ° labor7 ç›®å½•ï¼š")
    print(f"  1. ç¼–ç åå®Œæ•´æ•°æ®ï¼ˆå«loanåˆ—ï¼‰ï¼š{result_csv_path}")
    print(f"  2. å†³ç­–æ ‘å¯è§†åŒ–å›¾ç‰‡ï¼š{dt_img_path}")
    print(f"  3. å†³ç­–æ ‘DOTæ–‡ä»¶ï¼ˆé«˜æ¸…ï¼‰ï¼š{dot_path}")
    print(f"  4. ç‰¹å¾é‡è¦æ€§å›¾ç‰‡ï¼š{importance_img_path}")
    print(f"  5. ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼š{importance_csv_path}")
    print("=" * 70)
    print("ğŸ‰ å®éªŒå®Œæˆï¼æ‰€æœ‰æ–‡ä»¶å¯ç›´æ¥ç”¨äºå®éªŒæŠ¥å‘Šæ’°å†™ï¼š")
    print("  - å†³ç­–æ ‘å›¾ç‰‡ï¼šå±•ç¤ºæ¨¡å‹å†³ç­–é€»è¾‘")
    print("  - ç‰¹å¾é‡è¦æ€§å›¾ï¼šåˆ†æå½±å“è´·æ¬¾çš„æ ¸å¿ƒå› ç´ ")
    print("  - CSVç»“æœï¼šæä¾›ç¼–ç åçš„æ•°æ®å’Œç‰¹å¾é‡è¦æ€§æ•°å€¼")

# ---------------------- é”™è¯¯å¤„ç†ï¼ˆç²¾å‡†å®šä½é—®é¢˜ï¼‰----------------------
except FileNotFoundError:
    print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ï¼è¯·ç¡®è®¤ loan_YN.csv åœ¨ä»¥ä¸‹è·¯å¾„ï¼š{file_path}")
except ValueError as e:
    print(f"âŒ é”™è¯¯ï¼š{e}")
except Exception as e:
    print(f"âŒ æ„å¤–é”™è¯¯ï¼š{str(e)}")
    print("  æ’æŸ¥å»ºè®®ï¼š1. æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰ç©ºå€¼ï¼›2. ç¡®ä¿loanåˆ—æ˜¯åˆ†ç±»å˜é‡ï¼ˆå¦‚0/1ã€æ˜¯/å¦ï¼‰ï¼›3. ç¡®è®¤åˆ—åæ— ç©ºæ ¼")